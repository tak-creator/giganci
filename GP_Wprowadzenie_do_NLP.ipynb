{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tak-creator/giganci/blob/main/GP_Wprowadzenie_do_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f41de4f",
      "metadata": {
        "id": "1f41de4f"
      },
      "source": [
        "# Wprowadzenie do NLP w Pythonie\n",
        "- Tokenizacja, Lematyzacja i stemming\n",
        "- Embedding\n",
        "- Podobieństwo cosinusowe\n",
        "- Gra słowa: Ciepło - Zimno\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Tokenizacja, lematyzacja, stemming"
      ],
      "metadata": {
        "id": "-i50vfsGsN4o"
      },
      "id": "-i50vfsGsN4o"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4613333a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4613333a",
        "outputId": "d7184823-b77a-444e-eb13-ee92c316ac42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zdania: ['NLP to skrót od Natural Language Processing!', 'Po polsku to Przetwarzanie Języka Naturalnego']\n",
            "Tokeny: ['NLP', 'to', 'skrót', 'od', 'Natural', 'Language', 'Processing', '!', 'Po', 'polsku', 'to', 'Przetwarzanie', 'Języka', 'Naturalnego']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Biblioteka NLTK\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "text = \"NLP to skrót od Natural Language Processing! Po polsku to Przetwarzanie Języka Naturalnego\"\n",
        "print(\"Zdania:\", sent_tokenize(text))\n",
        "print(\"Tokeny:\", word_tokenize(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f37f6bc5",
      "metadata": {
        "id": "f37f6bc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050c9b67-f1db-4b3c-cb5d-6679f154b754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word       Lemma      Stem      \n",
            "Kupiłem    Kupiłem    kupiłem   \n",
            "Bułki      Bułki      bułki     \n",
            "bułeczki   bułeczki   bułeczki  \n",
            "brokuły    brokuły    brokułi   \n",
            "które      które      które     \n",
            "byłby      byłby      byłbi     \n",
            "czurczakowe czurczakowe czurczakow\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "nltk.download('wordnet')\n",
        "\n",
        "words = [\"Kupiłem\", \"Bułki\", \"bułeczki\", \"brokuły\", \"które\",\"byłby\",\"czurczakowe\"]\n",
        "print(\"{:<10} {:<10} {:<10}\".format(\"Word\", \"Lemma\", \"Stem\"))\n",
        "for w in words:\n",
        "    print(\"{:<10} {:<10} {:<10}\".format(w, lemmatizer.lemmatize(w, pos='v'), stemmer.stem(w)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Embedding - słowa na wektory"
      ],
      "metadata": {
        "id": "mab1LD_ulnbQ"
      },
      "id": "mab1LD_ulnbQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Usuń wszystkie wersje scipy i numpy\n",
        "!pip uninstall -y scipy numpy -q\n",
        "\n",
        "# Zainstaluj konkretne wersje zgodne z gensim\n",
        "!pip install numpy==1.26.4 scipy==1.12.0 --no-deps --force-reinstall --no-cache-dir -q\n",
        "\n",
        "# Zainstaluj gensim w wersji 4.3.2 – stabilna i zgodna\n",
        "!pip install gensim==4.3.2 --no-deps --force-reinstall --no-cache-dir -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf5WMwkVqmuF",
        "outputId": "78aca2f0-5370-4096-8259-15b193c4899c"
      },
      "id": "jf5WMwkVqmuF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m260.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m226.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m277.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Restartuję runtime\")\n",
        "#os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "UhU-IVuKqnpn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00455df3-8fd8-425b-9ee2-e32971f4f2af"
      },
      "id": "UhU-IVuKqnpn",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restartuję runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tylko sprawdzenie wersji\n",
        "import scipy\n",
        "print(\"✅ SciPy version:\", scipy.__version__)  # powinno dać 1.12.0\n",
        "\n",
        "# Test ładowania modelu GloVe\n",
        "import gensim\n",
        "from gensim.downloader import load\n",
        "\n",
        "print(\"Ładowanie modelu GloVe...\")\n",
        "model = load(\"glove-wiki-gigaword-100\")\n",
        "\n"
      ],
      "metadata": {
        "id": "X9PoIIBzqquo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed17df0-77f9-4110-e577-ab8494e9bd91"
      },
      "id": "X9PoIIBzqquo",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SciPy version: 1.12.0\n",
            "Ładowanie modelu GloVe...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dog →\", model[\"dog\"][:10])\n",
        "print(\"dogs →\", model[\"dogs\"][:10])\n",
        "print(\"cat →\", model[\"cat\"][:10])\n",
        "print(\"music →\", model[\"music\"][:10])"
      ],
      "metadata": {
        "id": "noRSUNABL0gN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44da86f7-4760-49aa-cd83-20635a70ea9f"
      },
      "id": "noRSUNABL0gN",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog → [ 0.30817  0.30938  0.52803 -0.92543 -0.73671  0.63475  0.44197  0.10262\n",
            " -0.09142 -0.56607]\n",
            "dogs → [ 0.37861  0.30269  0.27838 -0.92052 -0.79141  0.75824  0.12946  0.28971\n",
            " -0.38836 -0.39586]\n",
            "cat → [ 0.23088   0.28283   0.6318   -0.59411  -0.58599   0.63255   0.24402\n",
            " -0.14108   0.060815 -0.7898  ]\n",
            "music → [ 0.12705   0.37253   0.23076  -0.10727   1.4273    0.7799   -0.055009\n",
            " -0.18909  -0.42828   0.28443 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slowo = input(\"Wpisz dowolne angielskie słowo: \").lower()\n",
        "\n",
        "if slowo in model:\n",
        "    print(f\"Najbardziej podobne słowa do '{slowo}' to:\")\n",
        "    podobne = model.most_similar(slowo, topn=5)\n",
        "    for s, podobienstwo in podobne:\n",
        "        print(f\"{s} (podobieństwo: {podobienstwo:.2f})\")\n",
        "else:\n",
        "    print(\"To słowo nie istnieje w modelu. Spróbuj inne!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPF3RugvKnRI",
        "outputId": "f4d256ca-a943-4cff-9c1f-41b33c013c33"
      },
      "id": "NPF3RugvKnRI",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wpisz dowolne angielskie słowo: video\n",
            "Najbardziej podobne słowa do 'video' to:\n",
            "videos (podobieństwo: 0.83)\n",
            "dvd (podobieństwo: 0.78)\n",
            "audio (podobieństwo: 0.77)\n",
            "tv (podobieństwo: 0.74)\n",
            "footage (podobieństwo: 0.74)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50821d9e",
      "metadata": {
        "id": "50821d9e"
      },
      "source": [
        "## 3. Podobieństwo cosinusowe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b8036f26",
      "metadata": {
        "id": "b8036f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78be0a17-45ce-424a-d2f1-1b7ac1fa5c0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Podobieństwo 'dog' vs 'cat': 0.8798075\n",
            "Podobieństwo 'dog' vs 'century': 0.12041345\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def cos_sim(a, b):\n",
        "  return cosine_similarity([a], [b])[0][0]\n",
        "print(\"Podobieństwo 'dog' vs 'cat':\", cos_sim(model['dog'], model['cat']))\n",
        "print(\"Podobieństwo 'dog' vs 'century':\", cos_sim(model['dog'], model['century']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ddbb2c",
      "metadata": {
        "id": "79ddbb2c"
      },
      "source": [
        "## 4. Gra: Ciepło–Zimno"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Zakładamy, że model i cos_sim są już załadowane:\n",
        "# odel = load(\"glove-wiki-gigaword-50\")\n",
        "# def cos_sim(a, b): return cosine_similarity([a], [b])[0][0]\n",
        "\n",
        "vocab = [w for w in model.index_to_key if w.isalpha() and len(w) > 3]\n",
        "target = random.choice(vocab)\n",
        "\n",
        "print(\"Zgadnij słowo (angielskie). Wpisz 'exit' by zakończyć.\")\n",
        "\n",
        "last_sim = None\n",
        "wrong_guesses = 0\n",
        "hint_progress = 0  # ile liter ma zostać pokazanych jako podpowiedź\n",
        "\n",
        "while True:\n",
        "    guess = input(\">>> \").lower().strip()\n",
        "\n",
        "    if guess == 'exit':\n",
        "        print(\"Koniec gry. Słowo to:\", target)\n",
        "        break\n",
        "\n",
        "    if guess == target:\n",
        "        print(\"Brawo! Zgadłeś/-aś!\")\n",
        "        break\n",
        "\n",
        "    if guess not in model:\n",
        "        print(\"Nie znam tego słowa.\")\n",
        "        continue\n",
        "\n",
        "    sim = cos_sim(model[guess], model[target])\n",
        "\n",
        "    if last_sim is None:\n",
        "        print(f\"Podobieństwo: {sim:.4f}\")\n",
        "    else:\n",
        "        print(\"Ciepło!\" if sim > last_sim else \"Zimno!\", f\"(sim = {sim:.4f})\")\n",
        "\n",
        "    last_sim = sim\n",
        "    wrong_guesses += 1\n",
        "\n",
        "    # Podpowiedź po 3. błędach i dalej\n",
        "    if wrong_guesses >= 3:\n",
        "        hint_progress = min(wrong_guesses - 2, len(target))  # nie wyjść poza długość słowa\n",
        "        hint = target[:hint_progress] + \"_\" * (len(target) - hint_progress)\n",
        "        print(f\"Podpowiedź: {hint}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THBz6Iu5gn2a",
        "outputId": "9e2dcecb-1ead-414f-bf95-ba5e5eaf709a"
      },
      "id": "THBz6Iu5gn2a",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zgadnij słowo (angielskie). Wpisz 'exit' by zakończyć.\n",
            ">>> hbaby\n",
            "Nie znam tego słowa.\n",
            ">>> baby\n",
            "Podobieństwo: -0.1524\n",
            ">>> babies\n",
            "Ciepło! (sim = 0.0402)\n",
            ">>> windows\n",
            "Zimno! (sim = -0.0559)\n",
            "Podpowiedź: s_______\n",
            ">>> sloths\n",
            "Ciepło! (sim = 0.0390)\n",
            "Podpowiedź: su______\n",
            ">>> sukienka\n",
            "Nie znam tego słowa.\n",
            ">>> exit\n",
            "Koniec gry. Słowo to: sulphate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Wersja kodu z wbudowaną listą angielskich słówek na poziomie A2"
      ],
      "metadata": {
        "id": "XOpQRfIvlIiK"
      },
      "id": "XOpQRfIvlIiK"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lista słów A2\n",
        "a2_words = {\n",
        "    \"ability\", \"able\", \"about\", \"above\", \"accident\", \"activity\", \"actor\", \"actress\", \"add\", \"address\", \"adult\",\n",
        "    \"advice\", \"aeroplane\", \"afraid\", \"after\", \"afternoon\", \"again\", \"against\", \"age\", \"ago\", \"agree\", \"air\",\n",
        "    \"airport\", \"album\", \"all\", \"all right\", \"almost\", \"along\", \"already\", \"alright\", \"also\", \"always\", \"amazing\",\n",
        "    \"ambulance\", \"amount\", \"and\", \"angry\", \"animal\", \"another\", \"answer\", \"any\", \"anybody\", \"anyone\", \"anything\",\n",
        "    \"anywhere\", \"apartment\", \"apple\", \"April\", \"area\", \"arm\", \"around\", \"arrive\", \"art\", \"article\", \"artist\",\n",
        "    \"as\", \"ask\", \"at\", \"aunt\", \"autumn\", \"away\", \"baby\", \"back\", \"bad\", \"bag\", \"bake\", \"ball\", \"banana\", \"band\",\n",
        "    \"bank\", \"bar\", \"base\", \"baseball\", \"basket\", \"basketball\", \"bath\", \"bathroom\", \"be\", \"bean\", \"bear\", \"beautiful\",\n",
        "    \"because\", \"become\", \"bed\", \"bedroom\", \"beer\", \"before\", \"begin\", \"behind\", \"believe\", \"bell\", \"below\", \"best\",\n",
        "    \"better\", \"between\", \"bicycle\", \"big\", \"bike\", \"bill\", \"bird\", \"birthday\", \"black\", \"blond\", \"blog\", \"blue\",\n",
        "    \"board\", \"boat\", \"body\", \"boil\", \"book\", \"boot\", \"bored\", \"boring\", \"both\", \"bottle\", \"box\", \"boy\", \"boyfriend\",\n",
        "    \"bread\", \"break\", \"breakfast\", \"bring\", \"brother\", \"brown\", \"build\", \"building\", \"bus\", \"business\", \"busy\",\n",
        "    \"but\", \"butter\", \"buy\", \"by\", \"bye\", \"cafe\", \"cake\", \"call\", \"camera\", \"can\", \"cannot\", \"cap\", \"capital\", \"car\",\n",
        "    \"card\", \"care\", \"careful\", \"carefully\", \"carry\", \"cat\", \"CD\", \"cent\", \"center\", \"century\", \"certainly\", \"chair\",\n",
        "    \"change\", \"chart\", \"cheap\", \"check\", \"cheese\", \"chicken\", \"child\", \"chocolate\", \"choose\", \"cinema\", \"city\",\n",
        "    \"class\", \"classmate\", \"classroom\", \"clean\", \"clear\", \"clearly\", \"climb\", \"clock\", \"close\", \"clothes\", \"cloud\",\n",
        "    \"club\", \"coat\", \"coffee\", \"cold\", \"college\", \"color\", \"come\", \"common\", \"company\", \"compare\", \"complete\",\n",
        "    \"computer\", \"concert\", \"conversation\", \"cook\", \"cooker\", \"cooking\", \"cool\", \"correct\", \"cost\", \"could\",\n",
        "    \"country\", \"course\", \"cousin\", \"cow\", \"cream\", \"create\", \"cricket\", \"cross\", \"crown\", \"cry\", \"cup\", \"customer\",\n",
        "    \"cut\", \"dad\", \"dance\", \"dancer\", \"dancing\", \"dangerous\", \"dark\", \"date\", \"daughter\", \"day\", \"dear\", \"decide\",\n",
        "    \"deep\", \"delicious\", \"describe\", \"description\", \"design\", \"desk\", \"dictionary\", \"die\", \"different\", \"difficult\",\n",
        "    \"dinner\", \"dirty\", \"discuss\", \"discussion\", \"dish\", \"do\", \"doctor\", \"dog\", \"dollar\", \"door\", \"down\", \"draw\",\n",
        "    \"dream\", \"dress\", \"drink\", \"drive\", \"driver\", \"during\", \"each\", \"ear\", \"early\", \"east\", \"easy\", \"eat\", \"egg\",\n",
        "    \"eighteen\", \"eighty\", \"either\", \"elephant\", \"eleven\", \"email\", \"end\", \"engine\", \"enjoy\", \"enough\", \"enter\",\n",
        "    \"environment\", \"eraser\", \"euro\", \"even\", \"evening\", \"event\", \"ever\", \"every\", \"everybody\", \"everyone\",\n",
        "    \"everything\", \"everywhere\", \"exam\", \"example\", \"excited\", \"exciting\", \"exercise\", \"expensive\", \"explain\",\n",
        "    \"extra\", \"eye\", \"face\", \"fact\", \"fall\", \"family\", \"famous\", \"far\", \"farm\", \"farmer\", \"fast\", \"fat\", \"father\",\n",
        "    \"favorite\", \"feel\", \"feeling\", \"festival\", \"few\", \"field\", \"fifteen\", \"fifth\", \"fifty\", \"fill\", \"film\",\n",
        "    \"final\", \"find\", \"fine\", \"finger\", \"finish\", \"fire\", \"first\", \"fish\", \"five\", \"flat\", \"flight\", \"floor\",\n",
        "    \"flower\", \"fly\", \"follow\", \"food\", \"foot\", \"football\", \"for\", \"forget\", \"form\", \"four\", \"fourteen\", \"free\",\n",
        "    \"Friday\", \"friend\", \"friendly\", \"from\", \"front\", \"fruit\", \"full\", \"fun\", \"funny\", \"future\", \"game\", \"garden\",\n",
        "    \"geography\", \"get\", \"gift\", \"girl\", \"girlfriend\", \"give\", \"glass\", \"glasses\", \"go\", \"good\", \"goodbye\",\n",
        "    \"grandfather\", \"grandmother\", \"grape\", \"great\", \"green\", \"group\", \"grow\", \"guess\", \"guitar\", \"hair\", \"half\",\n",
        "    \"hall\", \"hamburger\", \"hand\", \"happen\", \"happy\", \"hard\", \"hat\", \"hate\", \"have\", \"he\", \"head\", \"health\", \"healthy\",\n",
        "    \"hear\", \"heart\", \"hello\", \"help\", \"her\", \"here\", \"hi\", \"high\", \"history\", \"hobby\", \"hold\", \"holiday\", \"home\",\n",
        "    \"homework\", \"hope\", \"horse\", \"hospital\", \"hot\", \"hotel\", \"hour\", \"house\", \"how\", \"hundred\", \"hungry\", \"hurry\",\n",
        "    \"hurt\", \"husband\", \"I\", \"ice\", \"ice cream\", \"idea\", \"if\", \"important\", \"improve\", \"in\", \"include\", \"information\",\n",
        "    \"interested\", \"interesting\", \"internet\", \"into\", \"invite\", \"island\", \"it\", \"its\", \"jacket\", \"jam\", \"job\", \"join\",\n",
        "    \"journey\", \"juice\", \"jump\", \"just\", \"keep\", \"key\", \"kick\", \"kid\", \"kill\", \"kind\", \"kitchen\", \"know\", \"language\",\n",
        "    \"large\", \"last\", \"late\", \"later\", \"laugh\", \"lazy\", \"learn\", \"leave\", \"left\", \"leg\", \"lemon\", \"lesson\", \"let\",\n",
        "    \"letter\", \"library\", \"lie\", \"life\", \"light\", \"like\", \"line\", \"lion\", \"listen\", \"little\", \"live\", \"long\", \"look\",\n",
        "    \"lose\", \"lot\", \"love\", \"low\", \"lunch\", \"machine\", \"magazine\", \"main\", \"make\", \"man\", \"many\", \"map\", \"market\",\n",
        "    \"married\", \"match\", \"matter\", \"may\", \"maybe\", \"me\", \"meal\", \"mean\", \"meat\", \"medicine\", \"meet\", \"meeting\",\n",
        "    \"member\", \"message\", \"meter\", \"midnight\", \"milk\", \"million\", \"minute\", \"miss\", \"mistake\", \"model\", \"modern\",\n",
        "    \"moment\", \"money\", \"monkey\", \"month\", \"moon\", \"more\", \"morning\", \"most\", \"mother\", \"mountain\", \"mouse\",\n",
        "    \"mouth\", \"move\", \"movie\", \"much\", \"mum\", \"museum\", \"music\", \"must\", \"my\", \"name\", \"narrow\", \"national\",\n",
        "    \"nature\", \"near\", \"neck\", \"need\", \"negative\", \"never\", \"new\", \"news\", \"newspaper\", \"next\", \"nice\", \"night\",\n",
        "    \"no\", \"noise\", \"noisy\", \"north\", \"nose\", \"not\", \"note\", \"nothing\", \"now\", \"number\", \"nurse\", \"object\",\n",
        "    \"ocean\", \"of\", \"off\", \"offer\", \"office\", \"often\", \"oh\", \"oil\", \"old\", \"on\", \"one\", \"only\", \"open\", \"or\",\n",
        "    \"orange\", \"order\", \"other\", \"our\", \"out\", \"outside\", \"over\", \"own\", \"page\", \"paint\", \"pair\", \"paper\",\n",
        "    \"parent\", \"park\", \"part\", \"partner\", \"party\", \"pass\", \"past\", \"pen\", \"pencil\", \"people\", \"pepper\", \"perfect\",\n",
        "    \"person\", \"pet\", \"phone\", \"photo\", \"photograph\", \"photographer\", \"physics\", \"picture\", \"piece\", \"pig\", \"pilot\",\n",
        "    \"pink\", \"pizza\", \"place\", \"plane\", \"plant\", \"plastic\", \"plate\", \"play\", \"player\", \"please\", \"plenty\", \"pocket\",\n",
        "    \"police\", \"polite\", \"pool\", \"poor\", \"pop\", \"popular\", \"possible\", \"post\", \"postcard\", \"potato\", \"pound\",\n",
        "    \"practice\", \"prefer\", \"prepare\", \"present\", \"pretty\", \"print\", \"problem\", \"program\", \"project\", \"pull\",\n",
        "    \"purple\", \"push\", \"put\", \"quarter\", \"question\", \"quick\", \"quiet\", \"radio\", \"rain\", \"rainy\", \"read\", \"ready\",\n",
        "    \"real\", \"really\", \"receive\", \"red\", \"remember\", \"repeat\", \"report\", \"rest\", \"restaurant\", \"return\", \"rice\",\n",
        "    \"ride\", \"right\", \"river\", \"road\", \"room\", \"run\", \"sad\", \"safe\", \"salad\", \"salt\", \"same\", \"sandwich\", \"Saturday\",\n",
        "    \"save\", \"say\", \"school\", \"science\", \"scientist\", \"score\", \"sea\", \"season\", \"seat\", \"second\", \"see\", \"sell\",\n",
        "    \"send\", \"sentence\", \"September\", \"seven\", \"seventeen\", \"seventy\", \"several\", \"shake\", \"shall\", \"shampoo\",\n",
        "    \"share\", \"she\", \"sheep\", \"shirt\", \"shoe\", \"shop\", \"shopping\", \"short\", \"should\", \"shoulder\", \"show\", \"sick\",\n",
        "    \"side\", \"sign\", \"silver\", \"similar\", \"simple\", \"since\", \"sing\", \"singer\", \"sister\", \"sit\", \"six\", \"sixteen\",\n",
        "    \"sixty\", \"size\", \"skate\", \"skateboard\", \"ski\", \"skirt\", \"sky\", \"sleep\", \"slow\", \"small\", \"smile\", \"snow\",\n",
        "    \"so\", \"soap\", \"soccer\", \"social\", \"some\", \"somebody\", \"someone\", \"something\", \"sometimes\", \"son\", \"song\",\n",
        "    \"soon\", \"sorry\", \"sound\", \"soup\", \"south\", \"space\", \"speak\", \"special\", \"spell\", \"spend\", \"sport\", \"spring\",\n",
        "    \"stand\", \"star\", \"start\", \"station\", \"stay\", \"steak\", \"still\", \"stomach\", \"stop\", \"store\", \"story\", \"straight\",\n",
        "    \"strange\", \"street\", \"strong\", \"student\", \"study\", \"stupid\", \"style\", \"subject\", \"success\", \"sugar\", \"summer\",\n",
        "    \"sun\", \"Sunday\", \"supermarket\", \"sure\", \"surprise\", \"swim\", \"swimming\", \"table\", \"take\", \"talk\", \"tall\", \"tape\",\n",
        "    \"taste\", \"taxi\", \"tea\", \"teach\", \"teacher\", \"team\", \"tell\", \"ten\"\n",
        "}\n",
        "\n",
        "# Filtrowanie słów obecnych w modelu\n",
        "vocab = [w for w in a2_words if w in model.key_to_index]\n",
        "target = random.choice(vocab)\n",
        "\n",
        "print(\"Zgadnij słowo. Wpisz 'exit', by zakończyć.\")\n",
        "\n",
        "# Funkcja podobieństwa\n",
        "def cos_sim(a, b):\n",
        "    return cosine_similarity([a], [b])[0][0]\n",
        "\n",
        "# Zmienna pomocnicza\n",
        "last_sim = None\n",
        "wrong_guesses = 0\n",
        "hint_progress = 0\n",
        "\n",
        "# Główna pętla gry\n",
        "while True:\n",
        "    guess = input(\">>> \").lower().strip()\n",
        "\n",
        "    if guess == 'exit':\n",
        "        print(\"Koniec gry. Szukane słowo to:\", target)\n",
        "        break\n",
        "\n",
        "    if guess == target:\n",
        "        print(\"Brawo! Zgadłeś/-aś słowo!\")\n",
        "        break\n",
        "\n",
        "    if guess not in model:\n",
        "        print(\"Nie znam tego słowa.\")\n",
        "        continue\n",
        "\n",
        "    sim = cos_sim(model[guess], model[target])\n",
        "\n",
        "    if last_sim is None:\n",
        "        print(f\"Podobieństwo: {sim:.4f}\")\n",
        "    else:\n",
        "        print(\"Ciepło!\" if sim > last_sim else \"Zimno!\", f\"(sim = {sim:.4f})\")\n",
        "\n",
        "    last_sim = sim\n",
        "    wrong_guesses += 1\n",
        "\n",
        "    if wrong_guesses >= 3:\n",
        "        hint_progress = min(wrong_guesses - 2, len(target))\n",
        "        hint = target[:hint_progress] + \"_\" * (len(target) - hint_progress)\n",
        "        print(f\"Podpowiedź: {hint}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gNBVYfspdyG",
        "outputId": "4ec1fdc9-f8eb-4b4a-9f62-2af16d6b6920",
        "collapsed": true
      },
      "id": "-gNBVYfspdyG",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zgadnij słowo. Wpisz 'exit', by zakończyć.\n",
            ">>> able\n",
            "Podobieństwo: 0.2712\n",
            ">>> wood\n",
            "Ciepło! (sim = 0.3967)\n",
            ">>> window\n",
            "Ciepło! (sim = 0.4683)\n",
            "Podpowiedź: p____\n",
            ">>> \n",
            "Nie znam tego słowa.\n",
            ">>> party\n",
            "Zimno! (sim = 0.1572)\n",
            "Podpowiedź: pl___\n",
            ">>> plant\n",
            "Ciepło! (sim = 0.2253)\n",
            "Podpowiedź: pla__\n",
            ">>> planty\n",
            "Zimno! (sim = -0.1894)\n",
            "Podpowiedź: plat_\n",
            ">>> plants\n",
            "Ciepło! (sim = 0.1913)\n",
            "Podpowiedź: plate\n",
            ">>> plate\n",
            "Brawo! Zgadłeś/-aś słowo!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7a58d82"
      },
      "source": [
        "# Install required libraries if not already installed\n",
        "print(\"Installing gensim and compatible numpy/scipy versions...\")\n",
        "# Uninstall conflicting versions\n",
        "!pip uninstall -y scipy numpy -q\n",
        "# Install specific versions compatible with gensim\n",
        "!pip install numpy==1.26.4 scipy==1.12.0 --no-deps --force-reinstall --no-cache-dir -q\n",
        "# Install gensim\n",
        "!pip install gensim==4.3.2 --no-deps --force-reinstall --no-cache-dir -q"
      ],
      "id": "d7a58d82",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}